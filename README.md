Playing around with RL stuff. See test.m for examples

So far:

TD.m -- TD(0) with SARSA, Q-learning, Actor-Critic, and generalized policy iteration from Sutton & Barto (2013) 

HMLMDP.m -- Hierarchical multitask LMDP's from Saxe et al (2017)

Options.m -- Hierarchical Q-learning with options, from Sutton et al (1999)


