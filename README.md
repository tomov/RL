Playing around with RL stuff

So far:
TD.m -- TD(0) with SARSA, Q-learning, and Actor-Critic from Sutton & Barto (2013) 
HMLMDP.m -- Hierarchical multitask LMDP's from Saxe et al (2017)
Options.m -- Hierarchical Q-learning with options, from Sutton et al (1999)

See test.m for examples
