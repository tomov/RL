Playing around with RL stuff. See test.m for examples

So far:

MDP.m -- TD(0) with SARSA, Q-learning, Actor-Critic, and generalized policy iteration from Sutton & Barto (2013) 

HMLMDP.m -- Hierarchical multitask LMDP's from Saxe et al (2017) with optional subtask decomposition from Earle et al (2017)

SMDP.m -- Hierarchical Q-learning with options (SMDP Q-learning), from Sutton et al (1999), also hierarchical semi-markov Q-learning (HSMQ) from Dietterich (2000)

MAXQ.m -- MAXQ from Dietterich (2000)


